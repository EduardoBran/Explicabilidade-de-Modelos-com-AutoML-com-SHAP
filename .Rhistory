head(df)
# Ajustar níveis das variáveis categóricas
df$Duration_f <- as.factor(df$Duration_f)
df$CreditAmount_f <- as.factor(df$CreditAmount_f)
# Interface do Usuário Shiny
ui <- fluidPage(
titlePanel("Previsão de Risco de Crédito"),
sidebarLayout(
sidebarPanel(
# Adicione aqui os controles para entrada de dados, por exemplo:
selectInput("checking_acct_stat", "Status da Conta Corrente",
choices = c("Menor que 0" = "A11",
"Entre 0 e 200" = "A12",
"Maior que 200" = "A13",
"Não possui" = "A14")),
sliderInput("duration", "Duração do Crédito", min = 0, max = 100, value = 50),
selectInput("purpose", "Finalidade do Crédito",
choices = c("Carro (novo)" = "A40",
"Carro (usado)" = "A41",
"Móveis/Equipamentos" = "A42",
"Rádio/Televisão" = "A43",
"Eletrodomésticos" = "A44",
"Reparos" = "A45",
"Educação" = "A46",
"Férias" = "A47",
"Reciclagem/Retreinamento" = "A48",
"Negócios" = "A49",
"Outros" = "A410")),
selectInput("credit_history", "Histórico de Crédito",
choices = c("Sem créditos tomados / todos os créditos pagos pontualmente." = "A30",
"Todos os créditos neste banco foram pagos pontualmente." = "A31",
"Créditos existentes pagos pontualmente até agora." = "A32",
"Atraso no pagamento no passado." = "A33",
"Conta crítica / outros créditos existentes (não neste banco)." = "A34")),
selectInput("savings_bonds", "Títulos de Poupança",
choices = c("Menos de 100 DM (Deutsche Marks) na conta poupança/títulos." = "A61",
"Entre 100 DM e menos de 500 DM na conta poupança/títulos." = "A62",
"Entre 500 DM e menos de 1000 DM na conta poupança/títulos." = "A63",
"1000 DM ou mais na conta poupança/títulos." = "A64",
"Desconhecido/nenhuma conta poupança." = "A65")),
selectInput("employment", "Emprego Atual",
choices = c("Desempregado." = "A71",
"Menos de 1 ano no emprego atual." = "A72",
"Entre 1 e menos de 4 anos no emprego atual." = "A73",
"Entre 4 e menos de 7 anos no emprego atual." = "A74",
"7 anos ou mais no emprego atual." = "A75")),
sliderInput("credit_amount", "Valor do Crédito", min = 0, max = 1000000, value = 500000),
# Adicione mais controles conforme necessário
actionButton("predict_button", "Realizar Previsão")
),
mainPanel(
# Adicione aqui os resultados da previsão, por exemplo:
verbatimTextOutput("prediction_output")
)
)
)
# Servidor Shiny
server <- function(input, output) {
# Reaja ao botão de previsão
observeEvent(input$predict_button, {
# Crie um novo conjunto de dados com base nas entradas do usuário
new_data <- data.frame(
CheckingAcctStat = factor(input$checking_acct_stat, levels = levels(df$CheckingAcctStat)),
Duration_f = as.factor(ifelse(as.integer(input$duration) <= 17.6, "(0,17.6]",
ifelse(as.integer(input$duration) <= 31.2, "(17.6,31.2]",
ifelse(as.integer(input$duration) <= 46.8, "(31.2,46.8]",
ifelse(as.integer(input$duration) <= 62.4, "(46.8,62.4]", "(62.4,100]"))))),
Purpose = factor(input$purpose, levels = levels(df$Purpose)),
CreditHistory = factor(input$credit_history, levels = levels(df$CreditHistory)),
SavingsBonds = factor(input$savings_bonds, levels = levels(df$SavingsBonds)),
Employment = factor(input$employment, levels = levels(df$Employment)),
CreditAmount_f = as.factor(ifelse(as.integer(input$credit_amount) <= 3880, "(0,3.88e+03]",
ifelse(as.integer(input$credit_amount) <= 6510, "(3.88e+03,6.51e+03]",
ifelse(as.integer(input$credit_amount) <= 9140, "(6.51e+03,9.14e+03]",
ifelse(as.integer(input$credit_amount) <= 11770, "(9.14e+03,1.18e+04]", "(1.18e+04,1e+06]"))))))
# Ajustar níveis novamente para garantir correspondência
for (col in names(new_data)) {
if (is.factor(new_data[[col]])) {
levels(new_data[[col]]) <- levels(df[[col]])
}
}
# Realize a previsão usando o modelo
prediction <- tryCatch(
predict(modelo, new_data),
error = function(e) {
return(paste("Erro na previsão:", e))
}
)
# Traduza a previsão para mensagens mais compreensíveis
prediction_message <- switch(as.character(prediction),
"1" = "Crédito Aprovado!",
"2" = "Crédito Reprovado!",
"Erro na previsão: New factor levels not present in the training data" = "Erro na previsão: Novos níveis de fatores não presentes nos dados de treinamento",
"Erro na previsão: Type of predictors in new data do not match that of the training data" = "Erro na previsão: O tipo de preditores nos novos dados não corresponde ao dos dados de treinamento",
"Erro na previsão:" = "Erro na previsão: Ocorreu um erro durante a previsão")
# Mostre a previsão na saída
output$prediction_output <- renderText({
paste("Resultado da Previsão: ", prediction_message)
})
})
}
# Execute o aplicativo Shiny
shinyApp(ui, server)
# Execute o aplicativo Shiny
shinyApp(ui, server)
setwd("~/Desktop/DataScience/CienciaDeDados/1.Big-Data-Analytics-com-R-e-Microsoft-Azure-Machine-Learning/19.Mini-Projeto-3_-_Explicabilidade_de_Modelos_AutoML_com_SHAP")
getwd()
## Carregar Pacotes
library(h2o)            # framework para construir modelos de machine learning
library(tidyverse)      # manipulação de dados
library(ggbeeswarm)     # pacote que permite criar gráficos customizados sobre o ggplot2
library(ggplot2)        # gera gráficos
library(dplyr)          # manipulação de dados
library(randomForest)   # carrega algoritimo de ML
library(ROCR)           # Gerando uma curva ROC em R
library(caret)          # Cria confusion matrix
library(shapper)
#### Exemplo 1 (mesma lógica do projeto)
## Etapa 1: Criação dos Dados Fictícios
dados <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
# Modificando variáveis prioridade e manutencao para tipo factor (é obrigatório a variável alvo está tipo factor para uso do h2o)
dados <- dados %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor) # modifica todas as variáveis do tipo chr para factor
str(dados)
## Etapa 2: Inicialização do h2o
h2o.init()
# Converta o dataframe para um objeto h2o
dados_h2o <- as.h2o(dados)
split <- h2o.splitFrame(data = dados_h2o, ratios = c(0.85), seed = 123)
conjunto_treino <- h2o.assign(split[[1]], "treino")
conjunto_teste <- h2o.assign(split[[2]], "teste")
rm(split)
## Etapa 4: Treinamento do Modelo AutoML com h2o
# Treine o modelo AutoML usando h2o
autoML_modelo <- h2o.automl(x = names(dados_h2o)[1:5],
y = "manutencao",
training_frame = conjunto_treino,
max_runtime_secs = 60)
# Visualiza a lista de Algoritmos
leaderboard_automl <- as.data.frame(autoML_modelo@leaderboard)
head(leaderboard_automl)
## Etapa 5: Avaliação do Modelo
# Avalie o desempenho do modelo no conjunto de teste
predicoes_teste <- h2o.predict(autoML_modelo, newdata = conjunto_teste)
predicoes_teste_df <- as.data.frame(h2o.cbind(conjunto_teste, predicoes_teste))
confusion_matrix <- table(predicoes_teste_df$predict, predicoes_teste_df$manutencao)
print(confusion_matrix)
# Calcula a acurácia a partir da matriz de confusão
sum(diag(confusion_matrix)) / sum(confusion_matrix)    # 51%
# Selecione as cinco variáveis mais importantes do modelo líder
variaveis_importantes <- leaderboard_automl %>%
filter(model_id == leaderboard_automl[1, "model_id"]) %>%
select(-model_id, -auc, -logloss, -aucpr, -mean_per_class_error, -rmse, -mse) %>%
gather(key = "variavel", value = "importancia") %>%
arrange(desc(importancia)) %>%
slice(1:5)
# Selecione as cinco variáveis mais importantes do modelo líder
variaveis_importantes <- leaderboard_automl %>%
filter(model_id == leaderboard_automl[1, "model_id"]) %>%
select(-model_id, -auc, -logloss, -aucpr, -mean_per_class_error, -rmse, -mse) %>%
gather(key = "variavel", value = "importancia") %>%
arrange(desc(importancia)) %>%
slice(1:5)
head(dados)
# Selecione as cinco variáveis mais importantes do modelo líder
variaveis_importantes <- leaderboard_automl %>%
filter(model_id == leaderboard_automl[1, "model_id"]) %>%
select(starts_with("variable_importance_")) %>%
gather(key = "variavel", value = "importancia") %>%
arrange(desc(importancia)) %>%
slice(1:5)
# Visualiza a lista de Algoritmos
leaderboard_automl <- as.data.frame(autoML_modelo@leaderboard)
head(leaderboard_automl)
head(dados)
# Selecione as cinco variáveis mais importantes do modelo líder
variaveis_importantes <- leaderboard_automl %>%
filter(model_id == leaderboard_automl[1, "model_id"]) %>%
select(starts_with("variable_importance_")) %>%
gather(key = "variavel", value = "importancia") %>%
arrange(desc(importancia)) %>%
slice(1:5)
# Obter a importância das variáveis do modelo líder
importancia_variaveis <- h2o.varimp(autoML_modelo@leader, use_pandas = FALSE)
# Obter a importância das variáveis do modelo líder
importancia_variaveis <- h2o.varimp(autoML_modelo@leader)
# Converter para um dataframe do R
variaveis_importantes <- as.data.frame(importancia_variaveis)
# Selecionar as cinco variáveis mais importantes
variaveis_importantes <- variaveis_importantes %>%
arrange(desc(variable_importance)) %>%
slice(1:5) %>%
select(variable, relative_importance)
variaveis_importantes
# Obter a importância das variáveis do modelo líder
importancia_variaveis <- h2o.varimp(autoML_modelo@leader)
# Converter para um dataframe do R
variaveis_importantes <- as.data.frame(importancia_variaveis)
variaveis_importantes
# Selecionar as cinco variáveis mais importantes
variaveis_importantes <- variaveis_importantes %>%
arrange(desc(variable_importance)) %>%
slice(1:5) %>%
select(variable, relative_importance)
# Selecionar as cinco variáveis mais importantes
variaveis_importantes <- variaveis_importantes %>%
arrange(desc(relative_importance)) %>%
slice(1:5) %>%
select(variable, relative_importance)
# Visualizar as variáveis mais importantes
print(variaveis_importantes)
# Crie um gráfico de barras para visualizar a importância das variáveis
ggplot(variaveis_importantes, aes(x = reorder(variavel, importancia), y = importancia)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +
labs(title = "Importância das Variáveis no Modelo",
x = "Variáveis",
y = "Importância") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Crie um gráfico de barras para visualizar a importância das variáveis
ggplot(variaveis_importantes, aes(x = reorder(variable, relative_importance), y = relative_importance)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +
labs(title = "Importância das Variáveis no Modelo",
x = "Variáveis",
y = "Importância") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Crie um gráfico de barras para visualizar a importância das variáveis
ggplot(variaveis_importantes, aes(x = reorder(relative_importance, variable), y = relative_importance)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +
labs(title = "Importância das Variáveis no Modelo",
x = "Variáveis",
y = "Importância") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Crie um gráfico de barras para visualizar a importância das variáveis
ggplot(variaveis_importantes, aes(x = reorder(variable, relative_importance), y = relative_importance)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +
labs(title = "Importância das Variáveis no Modelo",
x = "Variáveis",
y = "Importância") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Selecionar as 7 variáveis mais importantes
variaveis_importantes <- variaveis_importantes %>%
arrange(desc(relative_importance)) %>%
slice(1:7) %>%
select(variable, relative_importance)
# Visualizar as variáveis mais importantes
print(variaveis_importantes)
importancia_variaveis
# Selecionar as 7 variáveis mais importantes
variaveis_importantes <- variaveis_importantes %>%
arrange(desc(relative_importance)) %>%
select(variable, relative_importance)
# Visualizar as variáveis mais importantes
print(variaveis_importantes)
# Visualizar as variáveis mais importantes
View(variaveis_importantes)
head(dados)
# Obter a importância das variáveis do modelo líder
importancia_variaveis <- h2o.varimp(autoML_modelo@leader)
importancia_variaveis
# Converter para um dataframe do R
variaveis_importantes <- as.data.frame(importancia_variaveis)
variaveis_importantes
# Selecionar as variáveis mais importantes
variaveis_importantes <- variaveis_importantes %>%
arrange(desc(relative_importance)) %>%
select(variable, relative_importance)
# Visualizar as variáveis mais importantes
View(variaveis_importantes)
# Visualizar as variáveis mais importantes
print(variaveis_importantes)
# Visualizar as variáveis mais importantes
print(variaveis_importantes)
# Crie um gráfico de barras para visualizar a importância das variáveis
ggplot(variaveis_importantes, aes(x = reorder(variable, relative_importance), y = relative_importance)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +
labs(title = "Importância das Variáveis no Modelo",
x = "Variáveis",
y = "Importância") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
## Etapa Final: Plot da Importância das Variáveis
# Obter a importância das variáveis do modelo líder
importancia_variaveis <- h2o.varimp(autoML_modelo@leader)
importancia_variaveis
# Converter para um dataframe do R
variaveis_importantes <- as.data.frame(importancia_variaveis)
variaveis_importantes
# Selecionar as variáveis mais importantes
variaveis_importantes <- variaveis_importantes %>%
arrange(desc(relative_importance)) %>%
select(variable, relative_importance)
# Visualizar as variáveis mais importantes
print(variaveis_importantes)
# Desliga o H2O
h2o.shutdown()
y
Y[]
# Configurando o diretório de trabalho
setwd("~/Desktop/DataScience/CienciaDeDados/1.Big-Data-Analytics-com-R-e-Microsoft-Azure-Machine-Learning/19.Mini-Projeto-3_-_Explicabilidade_de_Modelos_AutoML_com_SHAP")
getwd()
## Carregando pacotes
library(h2o)            # framework para construir modelos de machine learning
library(tidyverse)      # manipulação de dados
library(ggbeeswarm)     # pacote que permite criar gráficos customizados sobre o ggplot2
library(ggplot2)        # gera gráficos
library(dplyr)          # manipulação de dados
library(randomForest)   # carrega algoritimo de ML
library(ROCR)           # Gerando uma curva ROC em R
library(caret)          # Cria confusion matrix
# -> O objetivo final deste mini projeto não consiste em estudar a fundo o AutoML, o objetivo real é mostrar o processo completo desde a definição
#    do problema de negócio até a entrega/explicabilidade. Além da criação do modelo, também daremos mais um passo explicando como o modelo faz
#    as previsões.
# -> Com o AutoML conseguiremos com uma única linha de código criar dezenas de modelos de Machine Learning.
#    Após isso iremos escolher o melhor modelo e então realizaremos uma Análise de Explicabilidade e entregar a Gerência como o modelo
#    chega ao seu resultado e sua conclusão.
## Criando Dados (como os dados serão gerados de forma randômica, o resultado será diferente a cada execução)
dados <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
# - 0 significa que o equipamento não requer manutenção (não)
# - 1 significa que o equipamento requer manutenção (sim)
# -> Pergunta de negócio: Quais fatores/métricas (variáveis) mais contribuem para explicar o comportamento da variável alvo? Por que?
#    Variável alvo      : manutencao
## Análise Exploratória
# Visualização dos dados
dim(dados)
str(dados)
table(dados$manutencao)
# Modificando variáveis prioridade e manutencao para tipo factor (é obrigatório a variável alvo está tipo factor para uso do h2o)
dados <- dados %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor) # modifica todas as variáveis do tipo chr para factor
str(dados)
## Inicializando o H2O (Framework de Machine Learning)
#  -> H20 é um framework de Machine Learning distribuído, no seu ambiente R.
#     O H2O é executado em uma máquina virtual Java (JVM) e fornece uma interface amigável para treinar modelos de Machine Learning.
h2o.init()
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dataset)
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dados)
class(h2o_frame)
head(h2o_frame)
# Split dos dados em treino e teste
h2o_frame_split <- h2o.splitFrame(h2o_frame, ratios = 0.77)
head(h2o_frame_split)
# Modelo AutoML
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60 * 2,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
modelo_automl
# Extrai o leaderboard
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
View(leaderboard_automl)
# Extrai o líder (modelo com melhor performance)
lider_automl <- modelo_automl@leader
View(lider_automl)
head(leaderboard_automl)
# Extrai o líder (modelo com melhor performance)
lider_automl <- modelo_automl@leader
print(lider_automl)
head(h2o_frame_split)
# Extrai o leaderboard (dataframe com os modelos criados)
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
head(leaderboard_automl)
View(leaderboard_automl)
# Extrai o líder (modelo com melhor performance)
lider_automl <- modelo_automl@leader
print(lider_automl)
View(lider_automl)
# Para o melhor modelo extraímos a contribuição de cada variável para as previsões
# os valores extraídos são chamados de valores SHAP
# Usamos os dados de teste
var_contrib <- predict_contributions.H2OModel(lider_automl, h2o_frame_split[[2]])
var_contrib
# Criando um dataframe com os as métricas que precisamos
df_var_contrib <- var_contrib %>%
as.data.frame() %>%
select(-BiasTerm) %>%
gather(feature, shap_value) %>%
group_by(feature) %>%
mutate(shap_importance = mean(abs(shap_value)), shap_force = mean(shap_value)) %>%
ungroup()
View(df_var_contrib)
# Plot da importância de cada variável para prever a variável alvo
df_var_contrib %>%
select(feature, shap_importance) %>%
distinct() %>%
ggplot(aes(x = reorder(feature, shap_importance), y = shap_importance)) +
geom_col(fill = 'blue') +
coord_flip() +
xlab(NULL) +
ylab("Valor Médio das Métricas SHAP") +
theme_minimal(base_size = 15)
# Plot da importância de cada variável para prever a variável alvo
df_var_contrib %>%
select(feature, shap_importance) %>%
distinct() %>%
ggplot(aes(x = reorder(feature, shap_importance), y = shap_importance)) +
geom_col(fill = 'blue') +
coord_flip() +
xlab(NULL) +
ylab("Valor Médio das Métricas SHAP") +
theme_minimal(base_size = 15)
# Plot de contribuição de cada variável para explicar a variável alvo
ggplot(df_var_contrib, aes(x = shap_value, y = reorder(feature, shap_importance))) +
ggbeeswarm::geom_quasirandom(groupOnX = FALSE, varwidth = TRUE, size = 0.9, alpha = 0.5, width = 0.15) +
xlab("Contribuição da Variável") +
ylab(NULL) +
theme_minimal(base_size = 15)
# Plot da importância de cada variável para prever a variável alvo
df_var_contrib %>%
select(feature, shap_importance) %>%
distinct() %>%
ggplot(aes(x = reorder(feature, shap_importance), y = shap_importance)) +
geom_col(fill = 'blue') +
coord_flip() +
xlab(NULL) +
ylab("Valor Médio das Métricas SHAP") +
theme_minimal(base_size = 15)
# Desliga o H2O
h2o.shutdown()
## Carregando pacotes
library(h2o)            # framework para construir modelos de machine learning
library(tidyverse)      # manipulação de dados
library(ggbeeswarm)     # pacote que permite criar gráficos customizados sobre o ggplot2
library(ggplot2)        # gera gráficos
library(dplyr)          # manipulação de dados
library(randomForest)   # carrega algoritimo de ML
library(ROCR)           # Gerando uma curva ROC em R
library(caret)          # Cria confusion matrix
# -> O objetivo final deste mini projeto não consiste em estudar a fundo o AutoML, o objetivo real é mostrar o processo completo desde a definição
#    do problema de negócio até a entrega/explicabilidade. Além da criação do modelo, também daremos mais um passo explicando como o modelo faz
#    as previsões.
# -> Com o AutoML conseguiremos com uma única linha de código criar dezenas de modelos de Machine Learning.
#    Após isso iremos escolher o melhor modelo e então realizaremos uma Análise de Explicabilidade e entregar a Gerência como o modelo
#    chega ao seu resultado e sua conclusão.
## Criando Dados (como os dados serão gerados de forma randômica, o resultado será diferente a cada execução)
dados <- tibble(produtividade = c(rnorm(1000), rnorm(1000, 0.25)),
rendimento = runif(2000),
custo = rf(2000, df1 = 5, df2 = 2),
prioridade = c(sample(rep(c('Baixa', 'Media', 'Alta'), c(300, 300, 400))),
sample(c('Baixa', 'Media', 'Alta'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),
eficiencia = rnorm(2000),
manutencao = rep(c(0,1), c(1050,950)))
# - 0 significa que o equipamento não requer manutenção (não)
# - 1 significa que o equipamento requer manutenção (sim)
# -> Pergunta de negócio: Quais fatores/métricas (variáveis) mais contribuem para explicar o comportamento da variável alvo? Por que?
#    Variável alvo      : manutencao
## Análise Exploratória
# Visualização dos dados
dim(dados)
str(dados)
table(dados$manutencao)
# Modificando variáveis prioridade e manutencao para tipo factor (é obrigatório a variável alvo está tipo factor para uso do h2o)
dados <- dados %>%
mutate(manutencao = as.factor(manutencao)) %>%
mutate_if(is.character, factor) # modifica todas as variáveis do tipo chr para factor
str(dados)
## Inicializando o H2O (Framework de Machine Learning)
#  -> H20 é um framework de Machine Learning distribuído, no seu ambiente R.
#     O H2O é executado em uma máquina virtual Java (JVM) e fornece uma interface amigável para treinar modelos de Machine Learning.
h2o.init()
#  -> Após inicializado, será criado uma espécie de página web na porta:  H2O Connection port: 54321
#     http://localhost:54321/
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dados)
class(h2o_frame)
head(h2o_frame)
# Split dos dados em treino e teste (cria duas listas)
h2o_frame_split <- h2o.splitFrame(h2o_frame, ratios = 0.77)
head(h2o_frame_split)
# Modelo AutoML
modelo_automl <- h2o.automl(y = 'manutencao',
balance_classes = TRUE,
training_frame = h2o_frame_split[[1]],
nfolds = 4,
leaderboard_frame = h2o_frame_split[[2]],
max_runtime_secs = 60 * 2,
include_algos = c('XGBoost', 'GBM', 'GLM'),
sort_metric = "AUC")
# Extrai o leaderboard (dataframe com os modelos criados)
leaderboard_automl <- as.data.frame(modelo_automl@leaderboard)
head(leaderboard_automl)
# Extrai o líder (modelo com melhor performance)
lider_automl <- modelo_automl@leader
print(lider_automl)
# Extraindo do melhor modelo a contribuição de cada variável para as previsões através dos dados de teste
# Estes valores são chamados de SHAP
var_contrib <- predict_contributions.H2OModel(lider_automl, h2o_frame_split[[2]])
# Desliga o H2O
h2o.shutdown()
