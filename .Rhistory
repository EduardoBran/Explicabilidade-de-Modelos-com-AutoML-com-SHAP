# Carregando o modelo
modelo <- readRDS("~/Desktop/DataScience/CienciaDeDados/1.Big-Data-Analytics-com-R-e-Microsoft-Azure-Machine-Learning/15.Projeto-de-Classificação-com-R-e-Azure-ML_-_Risco_de_Credito_Clientes_Banco/modelo.rds")
print(modelo)
# Carregando o dataset antes da transformação (baixado do Azure ML)
df <- read.csv("~/Desktop/DataScience/CienciaDeDados/1.Big-Data-Analytics-com-R-e-Microsoft-Azure-Machine-Learning/15.Projeto-de-Classificação-com-R-e-Azure-ML_-_Risco_de_Credito_Clientes_Banco/dados.csv", stringsAsFactors = TRUE)
head(df)
# Ajustar níveis das variáveis categóricas
df$Duration_f <- as.factor(df$Duration_f)
df$CreditAmount_f <- as.factor(df$CreditAmount_f)
# Interface do Usuário Shiny
ui <- fluidPage(
titlePanel("Previsão de Risco de Crédito"),
sidebarLayout(
sidebarPanel(
# Adicione aqui os controles para entrada de dados, por exemplo:
selectInput("checking_acct_stat", "Status da Conta Corrente",
choices = c("Menor que 0" = "A11",
"Entre 0 e 200" = "A12",
"Maior que 200" = "A13",
"Não possui" = "A14")),
sliderInput("duration", "Duração do Crédito", min = 0, max = 100, value = 50),
selectInput("purpose", "Finalidade do Crédito",
choices = c("Carro (novo)" = "A40",
"Carro (usado)" = "A41",
"Móveis/Equipamentos" = "A42",
"Rádio/Televisão" = "A43",
"Eletrodomésticos" = "A44",
"Reparos" = "A45",
"Educação" = "A46",
"Férias" = "A47",
"Reciclagem/Retreinamento" = "A48",
"Negócios" = "A49",
"Outros" = "A410")),
selectInput("credit_history", "Histórico de Crédito",
choices = c("Sem créditos tomados / todos os créditos pagos pontualmente." = "A30",
"Todos os créditos neste banco foram pagos pontualmente." = "A31",
"Créditos existentes pagos pontualmente até agora." = "A32",
"Atraso no pagamento no passado." = "A33",
"Conta crítica / outros créditos existentes (não neste banco)." = "A34")),
selectInput("savings_bonds", "Títulos de Poupança",
choices = c("Menos de 100 DM (Deutsche Marks) na conta poupança/títulos." = "A61",
"Entre 100 DM e menos de 500 DM na conta poupança/títulos." = "A62",
"Entre 500 DM e menos de 1000 DM na conta poupança/títulos." = "A63",
"1000 DM ou mais na conta poupança/títulos." = "A64",
"Desconhecido/nenhuma conta poupança." = "A65")),
selectInput("employment", "Emprego Atual",
choices = c("Desempregado." = "A71",
"Menos de 1 ano no emprego atual." = "A72",
"Entre 1 e menos de 4 anos no emprego atual." = "A73",
"Entre 4 e menos de 7 anos no emprego atual." = "A74",
"7 anos ou mais no emprego atual." = "A75")),
sliderInput("credit_amount", "Valor do Crédito", min = 0, max = 1000000, value = 500000),
# Adicione mais controles conforme necessário
actionButton("predict_button", "Realizar Previsão")
),
mainPanel(
# Adicione aqui os resultados da previsão, por exemplo:
verbatimTextOutput("prediction_output")
)
)
)
# Servidor Shiny
server <- function(input, output) {
# Reaja ao botão de previsão
observeEvent(input$predict_button, {
# Crie um novo conjunto de dados com base nas entradas do usuário
new_data <- data.frame(
CheckingAcctStat = factor(input$checking_acct_stat, levels = levels(df$CheckingAcctStat)),
Duration_f = as.factor(ifelse(as.integer(input$duration) <= 17.6, "(0,17.6]",
ifelse(as.integer(input$duration) <= 31.2, "(17.6,31.2]",
ifelse(as.integer(input$duration) <= 46.8, "(31.2,46.8]",
ifelse(as.integer(input$duration) <= 62.4, "(46.8,62.4]", "(62.4,100]"))))),
Purpose = factor(input$purpose, levels = levels(df$Purpose)),
CreditHistory = factor(input$credit_history, levels = levels(df$CreditHistory)),
SavingsBonds = factor(input$savings_bonds, levels = levels(df$SavingsBonds)),
Employment = factor(input$employment, levels = levels(df$Employment)),
CreditAmount_f = as.factor(ifelse(as.integer(input$credit_amount) <= 3880, "(0,3.88e+03]",
ifelse(as.integer(input$credit_amount) <= 6510, "(3.88e+03,6.51e+03]",
ifelse(as.integer(input$credit_amount) <= 9140, "(6.51e+03,9.14e+03]",
ifelse(as.integer(input$credit_amount) <= 11770, "(9.14e+03,1.18e+04]", "(1.18e+04,1e+06]"))))))
# Ajustar níveis novamente para garantir correspondência
for (col in names(new_data)) {
if (is.factor(new_data[[col]])) {
levels(new_data[[col]]) <- levels(df[[col]])
}
}
# Realize a previsão usando o modelo
prediction <- tryCatch(
predict(modelo, new_data),
error = function(e) {
return(paste("Erro na previsão:", e))
}
)
# Traduza a previsão para mensagens mais compreensíveis
prediction_message <- switch(as.character(prediction),
"1" = "Crédito Aprovado!",
"2" = "Crédito Reprovado!",
"Erro na previsão: New factor levels not present in the training data" = "Erro na previsão: Novos níveis de fatores não presentes nos dados de treinamento",
"Erro na previsão: Type of predictors in new data do not match that of the training data" = "Erro na previsão: O tipo de preditores nos novos dados não corresponde ao dos dados de treinamento",
"Erro na previsão:" = "Erro na previsão: Ocorreu um erro durante a previsão")
# Mostre a previsão na saída
output$prediction_output <- renderText({
paste("Resultado da Previsão: ", prediction_message)
})
})
}
# Execute o aplicativo Shiny
shinyApp(ui, server)
# Execute o aplicativo Shiny
shinyApp(ui, server)
# Configurando o diretório de trabalho
setwd("~/Desktop/DataScience/CienciaDeDados/1.Big-Data-Analytics-com-R-e-Microsoft-Azure-Machine-Learning/19.Mini-Projeto-3_-_Explicabilidade_de_Modelos_AutoML_com_SHAP")
getwd()
## Carregar pacotes
library(tidyverse)      # manipulação de dados
library(ggbeeswarm)     # pacote que permite criar gráficos customizados sobre o ggplot2
library(ggplot2)        # gera gráficos
library(dplyr)          # manipulação de dados
library(randomForest)   # carrega algoritimo de ML
library(ROCR)           # Gerando uma curva ROC em R
library(caret)          # cria confusion matrix
library(readxl)         # carregar arquivos
library(shiny)          # intercace gráfica
library(e1071)          # modelo svm
library(glmnet)         # carrega algoritimo de ML
library(xgboost)        # carrega algoritimo de ML
library(h2o)            # framework para construir modelos de machine learning
dados <- data.frame(read_csv("datasets/abalone/abalone.data", show_col_types = FALSE))
# Renomeando as colunas
colnames(dados) <- c("Sex", "Length", "Diameter", "Height", "Whole_weight",
"Shucked_weight", "Viscera_weight", "Shell_weight", "Rings")
head(dados)
# Removendo valores ausentes (caso necessário)
dados <- na.omit(dados)
# Modificando variáveis para tipo factor
dados <- dados %>%
mutate_if(is.character, factor)
str(dados)
summary(dados)
## SELEÇÃO DE VARIÁVEIS
modelo <- randomForest(Sex ~ ., data = dados, ntree = 100, nodesize = 10, importance = TRUE)
print(modelo$importance)
varImpPlot(modelo)
importancia_ordenada <- modelo$importance[order(-modelo$importance[, 1]), , drop = FALSE]
df_importancia <- data.frame(
Variavel = rownames(importancia_ordenada),
Importancia = importancia_ordenada[, 1]
)
ggplot(df_importancia, aes(x = reorder(Variavel, -Importancia), y = Importancia)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Importância das Variáveis", x = "Variável", y = "Importância") +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10))
rm(df_importancia)
rm(importancia_ordenada)
rm(modelo)
## Criando Modelos Preditivos
# Dividindo os dados em treino e teste
set.seed(150)
indices <- createDataPartition(dados$Sex, p = 0.80, list = FALSE)
dados_treino <- dados[indices, ]
dados_teste <- dados[-indices, ]
rm(indices)
# Modelo SVM
modelo_svm <- svm(Sex ~ ., data = dados_treino)
# Realizando as previsões
pred_svm <- predict(modelo_svm, newdata = dados_teste)
# Modelo RandomForest
modelo_rf <- randomForest(Sex ~ ., data = dados_treino, ntree = 100, nodesize = 10)
modelo_rf2 <- train(
Sex ~ .,
data = dados_treino,
method = "rf",  # Random Forest
trControl = trainControl(method = "cv", number = 5)
)
# Realizando as previsões
pred_rf <- predict(modelo_rf, newdata = dados_teste)
pred_rf2 <- predict(modelo_rf2, newdata = dados_teste)
# Modelo Gradient Boosting
modelo_gb <- train(
Sex ~ .,
data = dados_treino,
method = "gbm",  # Gradient Boosting Machine
trControl = trainControl(method = "cv", number = 5)
)
# Realizando as previsões
pred_gb <- predict(modelo_gb, newdata = dados_teste)
# Modelo k-Nearest Neighbors (k-NN)
modelo_knn <- train(
Sex ~ .,
data = dados_treino,
method = "knn",  # k-Nearest Neighbors
trControl = trainControl(method = "cv", number = 5)
)
# Realizando as previsões
pred_knn <- predict(modelo_knn, newdata = dados_teste)
# Modelo XGBoost
# Criar a matriz DMatrix para o XGBoost
dados_treino_xg <- dados_treino
dados_teste_xg <- dados_teste
# Codificar as classes numericamente
dados_treino_xg$Sex_numeric <- as.integer(factor(dados_treino$Sex, levels = c("F", "I", "M")))
dados_teste_xg$Sex_numeric <- as.integer(factor(dados_teste$Sex, levels = c("F", "I", "M")))
# Dividir os dados em treino e teste
set.seed(150)
indices <- createDataPartition(dados$Sex, p = 0.80, list = FALSE)
dados_treino_xg <- dados_treino_xg[indices, ]
dados_teste_xg <- dados_teste_xg[-indices, ]
rm(indices)
# Verificar se há valores NA ou NaN na variável de resposta
sum(is.na(dados_treino_xg$Sex_numeric) | is.nan(dados_treino_xg$Sex_numeric))
sum(!is.finite(dados_treino_xg$Sex_numeric))
dados_treino_xg <- dados_treino_xg[complete.cases(dados_treino_xg$Sex_numeric), ]
dados_teste_xg <- dados_teste_xg[complete.cases(dados_teste_xg$Sex_numeric), ]
# Verificar se há valores NA ou NaN na variável de resposta
sum(is.na(dados_treino_xg$Sex_numeric) | is.nan(dados_treino_xg$Sex_numeric))
sum(!is.finite(dados_treino_xg$Sex_numeric))
# Criar a matriz DMatrix para o XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(dados_treino_xg[, -c(1, 9)]), label = dados_treino_xg$Sex_numeric - 1)
dtest <- xgb.DMatrix(data = as.matrix(dados_teste_xg[, -c(1, 9)]), label = dados_teste_xg$Sex_numeric - 1)
# Definir os parâmetros do modelo
parametros <- list(
objective = "multi:softmax",  # Para problemas de classificação multiclasse
num_class = 3,                # Número de classes
eval_metric = "mlogloss"      # Métrica de avaliação
)
# Treinar o modelo XGBoost
modelo_xgb <- xgboost(data = dtrain, params = parametros, nrounds = 100, verbose = 0)
# Realizar previsões no conjunto de teste
pred_xgb <- predict(modelo_xgb, newdata = dtest)
## Avaliando o desempenho dos modelos
confusionMatrix(pred_svm, dados_teste$Sex)   # modelo_svm   -> Accuracy : 0.5719
confusionMatrix(pred_rf, dados_teste$Sex)    # modelo_rf    -> Accuracy : 0.5731
confusionMatrix(pred_rf2, dados_teste$Sex)   # modelo_rf2   -> Accuracy : 0.5719
confusionMatrix(pred_knn, dados_teste$Sex)   # modelo_knn   -> Accuracy : 0.5336
confusionMatrix(table(pred_xgb, dados_teste_xg$Sex_numeric - 1)) # Accuracy : 1
#  -> H20 é um framework de Machine Learning distribuído, no seu ambiente R.
#     O H2O é executado em uma máquina virtual Java (JVM) e fornece uma interface amigável para treinar modelos de Machine Learning.
h2o.init()
# O H2O requer que os dados estejam no formato de dataframe do H2O
h2o_frame <- as.h2o(dados)
# Split dos dados em treino e teste (cria duas listas)
h2o_frame_split <- h2o.splitFrame(h2o_frame, ratios = 0.77)
# Avaliar o desempenho no conjunto de teste
performance <- h2o.performance(lider_automl, newdata = h2o_frame_split[[2]])
lider_automl <- modelo_automl@leader
modelo_xgb_1 <- h2o.loadModel(paste0(caminho_do_diretorio, "/XGBoost_grid_1_AutoML_1_20240129_201835_model_12"))
# Carregar modelos
modelo_xgb_1 <- h2o.loadModel(paste0(caminho_do_diretorio, "automl_exemplo4_lider/XGBoost_grid_1_AutoML_1_20240129_201835_model_12"))
# Carregar modelos
modelo_xgb_1 <- h2o.loadModel(paste0("modelos/automl_exemplo4_lider", "/XGBoost_grid_1_AutoML_1_20240129_201835_model_12"))
modelo_gbm_9 <- h2o.loadModel(paste0("modelos/automl_exemplo4_gbm", "/GBM_grid_1_AutoML_1_20240129_201835_model_2"))
modelo_glm_12 <- h2o.loadModel(paste0("modelos/automl_exemplo4_glm", "/GLM_1_AutoML_1_20240129_201835_model_12"))
modelo_glm_12 <- h2o.loadModel(paste0("modelos/automl_exemplo4_glm", "/GLM_1_AutoML_1_20240129_201835_model_12"))
modelo_glm_12 <- h2o.loadModel(paste0("modelos/automl_exemplo4_glm", "/GLM_1_AutoML_1_20240129_201835"))
# Avaliar o desempenho no conjunto de teste
performance <- h2o.performance(GLM_1_AutoML_1_20240129_201835, newdata = h2o_frame_split[[2]])
# Avaliar o desempenho no conjunto de teste
performance <- h2o.performance(modelo_xgb_1, newdata = h2o_frame_split[[2]])
performance
## Avaliação do Modelo Binomial (Realizou Compra)
perf_rc <- h2o.performance(modelo_xgb_1)
perf_rc
performance_gbm <- h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
performance_glm <- h2o.performance(modelo_glm_12, newdata = h2o_frame_split[[2]])
performance_glm
# Visualizar a matriz de confusão
h2o.confusionMatrix(performance)
performance <- h2o.performance(modelo_xgb_1, newdata = h2o_frame_split[[2]])
performance_gbm <- h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
performance_glm <- h2o.performance(modelo_glm_12, newdata = h2o_frame_split[[2]])
performance
performance_gbm
performance_glm
modelo_gbm
modelo_gbm_9
str(dados)
modelo_gbm_9
performance_gbm
## Desliga o H2O
h2o.shutdown()
library(gbm)
# Converter 'Sex' para fatores numéricos
dados$Sex_numeric <- as.integer(factor(dados$Sex, levels = c("F", "I", "M")))
str(dados)
# Configurar os parâmetros do modelo GBM
gbm_params <- list(
distribution = "multinomial",
n.trees = 37,
interaction.depth = 9,
shrinkage = 0.2,
n.minobsinnode = 10
)
# Treinar o modelo GBM
modelo_gbm_manual <- gbm(
formula = as.formula(paste(response, "~", paste(predictors, collapse = " + "))),
data = dados,
distribution = gbm_params$distribution,
n.trees = gbm_params$n.trees,
interaction.depth = gbm_params$interaction.depth,
shrinkage = gbm_params$shrinkage,
n.minobsinnode = gbm_params$n.minobsinnode,
cv.folds = 4,
verbose = TRUE
)
response <- "Sex_numeric"
# Configurar os parâmetros do modelo GBM
gbm_params <- list(
distribution = "multinomial",
n.trees = 37,
interaction.depth = 9,
shrinkage = 0.2,
n.minobsinnode = 10
)
# Treinar o modelo GBM
modelo_gbm_manual <- gbm(
formula = as.formula(paste(response, "~", paste(predictors, collapse = " + "))),
data = dados,
distribution = gbm_params$distribution,
n.trees = gbm_params$n.trees,
interaction.depth = gbm_params$interaction.depth,
shrinkage = gbm_params$shrinkage,
n.minobsinnode = gbm_params$n.minobsinnode,
cv.folds = 4,
verbose = TRUE
)
# Converter 'Sex' para fatores numéricos
dados$Sex_numeric <- as.integer(factor(dados$Sex, levels = c("F", "I", "M")))
str(dados)
# Definir as colunas preditoras e a variável de resposta
predictors <- names(dados)[-c(1, 9)]  # Todas as colunas, exceto 'Sex' e 'Sex_numeric'
response <- "Sex_numeric"
# Configurar os parâmetros do modelo GBM
gbm_params <- list(
distribution = "multinomial",
n.trees = 37,
interaction.depth = 9,
shrinkage = 0.2,
n.minobsinnode = 10
)
# Treinar o modelo GBM
modelo_gbm_manual <- gbm(
formula = as.formula(paste(response, "~", paste(predictors, collapse = " + "))),
data = dados,
distribution = gbm_params$distribution,
n.trees = gbm_params$n.trees,
interaction.depth = gbm_params$interaction.depth,
shrinkage = gbm_params$shrinkage,
n.minobsinnode = gbm_params$n.minobsinnode,
cv.folds = 4,
verbose = TRUE
)
View(dados)
# Exibir o resumo do modelo
summary(modelo_gbm_manual)
# Exibir o resumo do modelo
summary(modelo_gbm_manual)
modelo_gbm_manual
# Converter 'Sex' para fatores numéricos
dados$Sex_numeric <- as.integer(factor(dados$Sex, levels = c("F", "I", "M")))
str(dados)
# Definir as colunas preditoras e a variável de resposta
predictors <- names(dados)[-c(1, 9)]  # Todas as colunas, exceto 'Sex' e 'Sex_numeric'
response <- "Sex_numeric"
# Configurar os parâmetros do modelo GBM
gbm_params <- list(
distribution = "multinomial",
n.trees = 37,
interaction.depth = 9,
shrinkage = 0.2,
n.minobsinnode = 10
)
# Treinar o modelo GBM
modelo_gbm_manual <- gbm(
formula = as.formula(paste(response, "~", paste(predictors, collapse = " + "))),
data = dados,
distribution = gbm_params$distribution,
n.trees = gbm_params$n.trees,
interaction.depth = gbm_params$interaction.depth,
shrinkage = gbm_params$shrinkage,
n.minobsinnode = gbm_params$n.minobsinnode,
cv.folds = 4,
verbose = TRUE
)
# Exibir o resumo do modelo
summary(modelo_gbm_manual)
performance_gbm
# Fazer previsões no conjunto de treinamento
predicoes <- predict(modelo_gbm_manual, dados, type = "response", n.trees = 37)
# MSE (Erro Quadrático Médio)
mse <- mean((dados$Sex_numeric - predicoes)^2)
cat("MSE:", mse, "\n")
# RMSE (Raiz do Erro Quadrático Médio)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# Converter 'Sex' para fatores numéricos
dados$Sex_numeric <- as.integer(factor(dados$Sex, levels = c("F", "I", "M")))
str(dados)
# Definir as colunas preditoras e a variável de resposta
predictors <- names(dados)[-c(1, 9)]  # Todas as colunas, exceto 'Sex' e 'Sex_numeric'
response <- "Sex_numeric"
# Dividindo os dados em treino e teste
set.seed(150)
indices <- createDataPartition(dados$Sex, p = 0.80, list = FALSE)
dados_treino <- dados[indices, ]
dados_teste <- dados[-indices, ]
rm(indices)
# Treinar o modelo GBM
modelo_gbm_manual <- gbm(
formula = as.formula(paste(response, "~", paste(predictors, collapse = " + "))),
data = dados_treino,
distribution = gbm_params$distribution,
n.trees = gbm_params$n.trees,
interaction.depth = gbm_params$interaction.depth,
shrinkage = gbm_params$shrinkage,
n.minobsinnode = gbm_params$n.minobsinnode,
cv.folds = 4,
verbose = TRUE
)
# Fazer previsões no conjunto de treinamento
predicoes <- predict(modelo_gbm_manual, dados_teste, type = "response", n.trees = 37)
# MSE (Erro Quadrático Médio)
mse <- mean((dados$Sex_numeric - predicoes)^2)
# MSE (Erro Quadrático Médio)
mse <- mean((dados_teste$Sex_numeric - predicoes)^2)
cat("MSE:", mse, "\n")
# RMSE (Raiz do Erro Quadrático Médio)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# Mean Per-Class Error
# Converter as previsões em classes preditas (usando regras específicas para problemas multinomiais)
classes_preditas <- colnames(predicoes)[apply(predicoes, 1, which.max)]
mean_per_class_error <- mean(classes_preditas != dados_teste$Sex_numeric)
cat("Mean Per-Class Error:", mean_per_class_error, "\n")
# Converter as previsões em classes preditas (usando regras específicas para problemas multinomiais)
classes_preditas <- colnames(predicoes)[apply(predicoes, 1, which.max)]
mean_per_class_error <- mean(classes_preditas != dados_treino$Sex_numeric)
cat("Mean Per-Class Error:", mean_per_class_error, "\n")
# MSE (Erro Quadrático Médio)
mse <- mean((dados_treino$Sex_numeric - predicoes)^2)
# Converter 'Sex' para fatores numéricos
dados$Sex_numeric <- as.integer(factor(dados$Sex, levels = c("F", "I", "M")))
str(dados)
# Definir as colunas preditoras e a variável de resposta
predictors <- names(dados)[-c(1, 9)]  # Todas as colunas, exceto 'Sex' e 'Sex_numeric'
response <- "Sex_numeric"
# Dividindo os dados em treino e teste
set.seed(150)
indices <- createDataPartition(dados$Sex, p = 0.80, list = FALSE)
dados_treino <- dados[indices, ]
dados_teste <- dados[-indices, ]
rm(indices)
# Configurar os parâmetros do modelo GBM
gbm_params <- list(
distribution = "multinomial",
n.trees = 37,
interaction.depth = 9,
shrinkage = 0.2,
n.minobsinnode = 10
)
# Treinar o modelo GBM
modelo_gbm_manual <- gbm(
formula = as.formula(paste(response, "~", paste(predictors, collapse = " + "))),
data = dados_treino,
distribution = gbm_params$distribution,
n.trees = gbm_params$n.trees,
interaction.depth = gbm_params$interaction.depth,
shrinkage = gbm_params$shrinkage,
n.minobsinnode = gbm_params$n.minobsinnode,
cv.folds = 4,
verbose = TRUE
)
# Exibir o resumo do modelo
summary(modelo_gbm_manual)
performance_gbm
# Fazer previsões no conjunto de teste
predicoes_teste <- predict(modelo_gbm_manual, dados_teste, n.trees = 37)
# MSE (Erro Quadrático Médio)
mse_teste <- mean((dados_teste$Sex_numeric - predicoes_teste)^2)
cat("MSE Teste:", mse_teste, "\n")
# RMSE (Raiz do Erro Quadrático Médio)
rmse_teste <- sqrt(mse_teste)
cat("RMSE Teste:", rmse_teste, "\n")
classes_preditas_teste <- colnames(predicoes_teste)[apply(predicoes_teste, 1, which.max)]
mean_per_class_error_teste <- mean(classes_preditas_teste != dados_teste$Sex_numeric)
cat("Mean Per-Class Error Teste:", mean_per_class_error_teste, "\n")
# Fazer previsões no conjunto de teste
predicoes_teste <- predict(modelo_gbm_manual, dados_teste, n.trees = 37)
# MSE (Erro Quadrático Médio)
mse_teste <- mean((dados_teste$Sex_numeric - predicoes_teste)^2)
cat("MSE Teste:", mse_teste, "\n")
# RMSE (Raiz do Erro Quadrático Médio)
rmse_teste <- sqrt(mse_teste)
cat("RMSE Teste:", rmse_teste, "\n")
# Logloss
# Como mencionado anteriormente, não há uma função direta para calcular logloss no pacote gbm. Você pode usar pacotes adicionais ou implementar manualmente.
# Mean Per-Class Error
# Converter as previsões em classes preditas (usando regras específicas para problemas multinomiais)
classes_preditas_teste <- colnames(predicoes_teste)[apply(predicoes_teste, 1, which.max)]
mean_per_class_error_teste <- mean(classes_preditas_teste != dados_teste$Sex_numeric)
cat("Mean Per-Class Error Teste:", mean_per_class_error_teste, "\n")
class(modelo_gbm_9)
class(modelo_gbm_manual)
# Para modelo_gbm_9
performance_gbm_9 <- h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
# Para modelo_gbm_9
h2o.init()
performance_gbm_9 <- h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
performance_gbm <- h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
h2o.performance(modelo_gbm_9, newdata = dados_treino)
h2o.performance(modelo_gbm_9, newdata = h2o_frame_split[[2]])
